{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMKjHKIOL4vp0fN25COeePT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaiminwoo0223/Deep-Learning/blob/main/11%20-%20ResNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Residual Networks\n",
        "\n",
        "- 2015 ILSVRC 1st place\n",
        "- ResNet-50\n",
        "\n",
        "![alt text](https://www.codeproject.com/KB/AI/1248963/resnet.png)\n"
      ],
      "metadata": {
        "id": "eqBEg_iFfz_R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "hQl_f5K0f6Lf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torch.utils.data as data\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "# from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "bRlZitPCgEmJ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Download"
      ],
      "metadata": {
        "id": "0DrGRiL6iMyc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r images\n",
        "\n",
        "try:\n",
        "    os.mkdir(\"images\")\n",
        "    os.mkdir(\"images/dogs\")\n",
        "    os.mkdir(\"images/cats\")\n",
        "except:\n",
        "    pass\n",
        "\n",
        "!wget https://i.kinja-img.com/gawker-media/image/upload/s--WFkXeene--/c_scale,f_auto,fl_progressive,q_80,w_800/ol9ceoqxidudap8owlwn.jpg -P images/dogs\n",
        "!wget https://www.rspcansw.org.au/wp-content/uploads/2017/08/50_a-feature_dogs-and-puppies_mobile.jpg -P images/dogs\n",
        "!wget https://www.catster.com/wp-content/uploads/2018/05/A-gray-cat-crying-looking-upset.jpg -P images/cats\n",
        "!wget https://www.scarymommy.com/wp-content/uploads/2018/01/c1.jpg?w=700 -P images/cats"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFjlQ0cmhUsT",
        "outputId": "f4d69215-8683-4784-dbe9-006fdafe7e35"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-04-21 09:02:20--  https://i.kinja-img.com/gawker-media/image/upload/s--WFkXeene--/c_scale,f_auto,fl_progressive,q_80,w_800/ol9ceoqxidudap8owlwn.jpg\n",
            "Resolving i.kinja-img.com (i.kinja-img.com)... 151.101.194.166, 151.101.66.166, 151.101.130.166, ...\n",
            "Connecting to i.kinja-img.com (i.kinja-img.com)|151.101.194.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 36509 (36K) [image/jpeg]\n",
            "Saving to: ‘images/dogs/ol9ceoqxidudap8owlwn.jpg’\n",
            "\n",
            "\rol9ceoqxidudap8owlw   0%[                    ]       0  --.-KB/s               \rol9ceoqxidudap8owlw 100%[===================>]  35.65K  --.-KB/s    in 0.001s  \n",
            "\n",
            "2023-04-21 09:02:20 (33.0 MB/s) - ‘images/dogs/ol9ceoqxidudap8owlwn.jpg’ saved [36509/36509]\n",
            "\n",
            "--2023-04-21 09:02:20--  https://www.rspcansw.org.au/wp-content/uploads/2017/08/50_a-feature_dogs-and-puppies_mobile.jpg\n",
            "Resolving www.rspcansw.org.au (www.rspcansw.org.au)... 101.0.86.38\n",
            "Connecting to www.rspcansw.org.au (www.rspcansw.org.au)|101.0.86.38|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 130940 (128K) [image/jpeg]\n",
            "Saving to: ‘images/dogs/50_a-feature_dogs-and-puppies_mobile.jpg’\n",
            "\n",
            "50_a-feature_dogs-a 100%[===================>] 127.87K   154KB/s    in 0.8s    \n",
            "\n",
            "2023-04-21 09:02:22 (154 KB/s) - ‘images/dogs/50_a-feature_dogs-and-puppies_mobile.jpg’ saved [130940/130940]\n",
            "\n",
            "--2023-04-21 09:02:22--  https://www.catster.com/wp-content/uploads/2018/05/A-gray-cat-crying-looking-upset.jpg\n",
            "Resolving www.catster.com (www.catster.com)... 18.65.39.96, 18.65.39.67, 18.65.39.80, ...\n",
            "Connecting to www.catster.com (www.catster.com)|18.65.39.96|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 165145 (161K) [image/jpeg]\n",
            "Saving to: ‘images/cats/A-gray-cat-crying-looking-upset.jpg’\n",
            "\n",
            "A-gray-cat-crying-l 100%[===================>] 161.27K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-04-21 09:02:22 (9.21 MB/s) - ‘images/cats/A-gray-cat-crying-looking-upset.jpg’ saved [165145/165145]\n",
            "\n",
            "--2023-04-21 09:02:22--  https://www.scarymommy.com/wp-content/uploads/2018/01/c1.jpg?w=700\n",
            "Resolving www.scarymommy.com (www.scarymommy.com)... 52.222.139.87, 52.222.139.61, 52.222.139.103, ...\n",
            "Connecting to www.scarymommy.com (www.scarymommy.com)|52.222.139.87|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2023-04-21 09:02:23 ERROR 404: Not Found.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter"
      ],
      "metadata": {
        "id": "IaD7piYMhUAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 1\n",
        "learning_rate = 0.002\n",
        "num_epoch = 100"
      ],
      "metadata": {
        "id": "YhQef_RmgQh4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Loader"
      ],
      "metadata": {
        "id": "GogVlknBiots"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_dir = \"./images\"\n",
        "img_data = dset.ImageFolder(img_dir, transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor()\n",
        "]))\n",
        "\n",
        "train_loader = data.DataLoader(img_data, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "test_loader = data.DataLoader(img_data, batch_size=batch_size, shuffle=False, num_workers=2)"
      ],
      "metadata": {
        "id": "YwkyE9HKitWS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "XA-00KVekj3C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1.Basic Block\n",
        "\n",
        "- 컨볼루션 연산과 활성화함수는 항상 붙어 있기 떄문에, 이를 함수로 만든다."
      ],
      "metadata": {
        "id": "G1sG7lPBkpuS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_block_1(in_dim, out_dim, act_fn, stride=1):\n",
        "    model = nn.Sequential(\n",
        "        nn.Conv2d(in_dim, out_dim, kernel_size=1, stride=stride),\n",
        "        act_fn\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def conv_block_3(in_dim, out_dim, act_fn):\n",
        "    model = nn.Sequential(\n",
        "        nn.Conv2d(in_dim, out_dim, kernel_size=3, stride=1, padding=1),\n",
        "        act_fn\n",
        "    )\n",
        "    return model"
      ],
      "metadata": {
        "id": "imVHTX0xj_aN"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.BottleNeck Module\n",
        "\n",
        "- BottleNeck 모듈 : 1X1 컨볼루션 -> 3X3 컨볼루션 -> 1X1컨볼루션\n",
        "- 네트워크 구조에서도 볼 수 있듯이, 실선은 크기가 변하지 않는 경우이고, 점선은 크기가 변하는 경우이다.\n",
        "- 이를 한번에 구현하기 위하여, down이라는 변수로 크기 감소 여부를 표시하고, 조건문으로 경우의 수를 나눈다.\n",
        "- 또한, ResNet의 Skip-Connection은 단순 더하기로 정의 되어있기 때문에, 특성지도의 크기를 일치시킨다.\n",
        "- 이를 위하여, 차원을 맞춰주는 역할을 하는 dim_equalizer를 정의한다."
      ],
      "metadata": {
        "id": "KLJdPBTanTJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class BottleNeck(nn.Module):\n",
        "    def __init__(self, in_dim, mid_dim, out_dim, act_fn, down=False):\n",
        "        super(BottleNeck,self).__init__()\n",
        "        self.down = down\n",
        "\n",
        "        if self.down: # 특성지도의 크기가 감소하는 경우\n",
        "            self.layer = nn.Sequential(\n",
        "                conv_block_1(in_dim, mid_dim, act_fn, 2),\n",
        "                conv_block_3(mid_dim, mid_dim, act_fn),\n",
        "                conv_block_1(mid_dim, out_dim, act_fn)\n",
        "            )\n",
        "            self.downsample = nn.Conv2d(in_dim, out_dim, 1, 2)\n",
        "        else: # 특성지도의 크기가 그대로인 경우\n",
        "            self.layer = nn.Sequential(\n",
        "                conv_block_1(in_dim, mid_dim, act_fn),\n",
        "                conv_block_3(mid_dim, mid_dim, act_fn),\n",
        "                conv_block_1(mid_dim, out_dim, act_fn)\n",
        "            )\n",
        "            self.dim_equalizer = nn.Conv2d(in_dim, out_dim, 1)\n",
        "\n",
        "    def forward(self,x):\n",
        "        if self.down:\n",
        "            downsample = self.downsample(x) \n",
        "            out = self.layer(x)\n",
        "            out = out + downsample\n",
        "        else:\n",
        "            out = self.layer(x)\n",
        "            if x.size() is not out.size():\n",
        "                x = self.dim_equalizer(x)\n",
        "            out = out + x\n",
        "        return out"
      ],
      "metadata": {
        "id": "Kcb7NE7fpHg2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.ResNet"
      ],
      "metadata": {
        "id": "luQtwMbju0cu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, base_dim, num_classes=2):\n",
        "        super(ResNet,self).__init__()\n",
        "        self.act_fn = nn.ReLU()\n",
        "        self.layer_1 = nn.Sequential(\n",
        "            nn.Conv2d(3,base_dim,7,2,3),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(3,2,1)\n",
        "        )\n",
        "        self.layer_2 = nn.Sequential(\n",
        "            BottleNeck(base_dim, base_dim, base_dim*4, self.act_fn),\n",
        "            BottleNeck(base_dim*4, base_dim, base_dim*4, self.act_fn),\n",
        "            BottleNeck(base_dim*4, base_dim, base_dim*4, self.act_fn, down=True)\n",
        "        )\n",
        "        self.layer_3 = nn.Sequential(\n",
        "            BottleNeck(base_dim*4, base_dim*2, base_dim*8, self.act_fn),\n",
        "            BottleNeck(base_dim*8, base_dim*2, base_dim*8, self.act_fn),\n",
        "            BottleNeck(base_dim*8, base_dim*2, base_dim*8, self.act_fn),\n",
        "            BottleNeck(base_dim*8, base_dim*2, base_dim*8, self.act_fn, down=True)\n",
        "        )\n",
        "        self.layer_4 = nn.Sequential(\n",
        "            BottleNeck(base_dim*8, base_dim*4, base_dim*16, self.act_fn),\n",
        "            BottleNeck(base_dim*16, base_dim*4, base_dim*16, self.act_fn),\n",
        "            BottleNeck(base_dim*16, base_dim*4, base_dim*16, self.act_fn),\n",
        "            BottleNeck(base_dim*16, base_dim*4, base_dim*16, self.act_fn),\n",
        "            BottleNeck(base_dim*16, base_dim*4, base_dim*16, self.act_fn),\n",
        "            BottleNeck(base_dim*16, base_dim*4, base_dim*16, self.act_fn, down=True)\n",
        "        )\n",
        "        self.layer_5 = nn.Sequential(\n",
        "            BottleNeck(base_dim*16, base_dim*8, base_dim*32, self.act_fn),\n",
        "            BottleNeck(base_dim*32, base_dim*8, base_dim*32, self.act_fn),\n",
        "            BottleNeck(base_dim*32, base_dim*8, base_dim*32, self.act_fn)\n",
        "        )\n",
        "        self.avgpool = nn.AvgPool2d(7,1)\n",
        "        self.fc_layer = nn.Linear(base_dim*32,num_classes)\n",
        "\n",
        "    def forward(self,x):\n",
        "        out = self.layer_1(x)\n",
        "        out = self.layer_2(out)\n",
        "        out = self.layer_3(out)\n",
        "        out = self.layer_4(out)\n",
        "        out = self.layer_5(out)\n",
        "        out = self.avgpool(out)\n",
        "        out = out.view(batch_size,-1)\n",
        "        out = self.fc_layer(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "gXNu4Wtbvn6M"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss & Optimizer"
      ],
      "metadata": {
        "id": "kdagIfqRvTPq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "model = ResNet(base_dim = 64).to(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GmE9ir70nQR8",
        "outputId": "03dbd6bd-c6b1-4bad-a8ee-a2a22e11b8ed"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "CgfEbHXE9MCd"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "hnxq4p5d-B6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_epoch):\n",
        "    for j, [image,label] in enumerate(train_loader):\n",
        "        x = image.to(device)\n",
        "        y_= label.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(x)\n",
        "        loss = loss_func(output,y_)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    if i % 10 == 0:\n",
        "        print(loss)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SARgFU-r-FvZ",
        "outputId": "1cfcefa6-524f-4209-ad71-62d585125e79"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.1921e-07, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(239410.5156, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(4303133.5000, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(26882432., device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.3382e+08, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(0., device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(6.0665e+10, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "tensor(1.2062e+12, device='cuda:0', grad_fn=<NllLossBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "pH69cDnECN9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for image,label in test_loader:\n",
        "        x = image.to(device)\n",
        "        y_= label.to(device)\n",
        "\n",
        "        output = model.forward(x)\n",
        "        _, output_index = torch.max(output,1)\n",
        "        total += label.size(0)\n",
        "        correct += (output_index == y_).sum().float()\n",
        "\n",
        "    print(\"Accuracy of the Data : {}%\".format(100*correct / total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "543eOlFUCQbD",
        "outputId": "04fcfd7c-5a9c-4cc3-b2ee-1392a46629f4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the Data : 66.66667175292969%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6IINtQx3DIkD"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}