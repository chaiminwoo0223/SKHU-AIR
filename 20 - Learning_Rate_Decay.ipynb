{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM66Up1InJmsbfGtPiU8JbG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chaiminwoo0223/Deep-Learning/blob/main/20%20-%20Learning_Rate_Decay.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import"
      ],
      "metadata": {
        "id": "We0CSlCNqHlj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9L6b4RL1pfpw"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torchvision.datasets as dset\n",
        "import torchvision.transforms as transforms\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import DataLoader"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Hyperparameter"
      ],
      "metadata": {
        "id": "L4ZRnPwNqHnz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 256\n",
        "lr = 0.001\n",
        "num_epoch = 10"
      ],
      "metadata": {
        "id": "GDccDrUIpvSV"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data\n",
        "## 1.Data Download"
      ],
      "metadata": {
        "id": "q1NIQ_USqHrb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train = dset.MNIST(\"./\", train=True, transform=transforms.ToTensor(), target_transform=None, download=True)\n",
        "mnist_test = dset.MNIST(\"./\", train=False, transform=transforms.ToTensor(), target_transform=None, download=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KB8SCUFOpvUd",
        "outputId": "1e9d3915-a6e9-4af2-f0a5-d087f8351b42"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 214296743.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-images-idx3-ubyte.gz to ./MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 56791230.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/train-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 68590300.38it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-images-idx3-ubyte.gz to ./MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 23665253.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./MNIST/raw/t10k-labels-idx1-ubyte.gz to ./MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.Check Dataset"
      ],
      "metadata": {
        "id": "7yNaevaFqH5A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(mnist_train.__getitem__(0)[0].size(), mnist_train.__len__())\n",
        "print(mnist_test.__getitem__(0)[0].size(), mnist_test.__len__())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PRBf1mqNpvWd",
        "outputId": "c1b8cf25-b2f0-4290-f0c1-61686b7955bf"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 28, 28]) 60000\n",
            "torch.Size([1, 28, 28]) 10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.Set DataLoader"
      ],
      "metadata": {
        "id": "MM1E76odqYRb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=2, drop_last=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=2, drop_last=True)"
      ],
      "metadata": {
        "id": "kDlLatU8pvYd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNN\n",
        "## 1.Model"
      ],
      "metadata": {
        "id": "vTzFRFIZqan1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.layer = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, padding=1),  # 28 X 28\n",
        "            nn.ReLU(),\n",
        "            nn.Conv2d(16, 32, 3, padding=1), # 28 X 28\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),              # 14 X 14\n",
        "            nn.Conv2d(32, 64, 3, padding=1), # 14 X 14\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d(2, 2),              #  7 X 7\n",
        "        )\n",
        "        self.fc_layer = nn.Sequential(\n",
        "            nn.Linear(64*7*7, 100),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(100, 10)\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        out = self.layer(x)\n",
        "        out = out.view(batch_size, -1)\n",
        "        out = self.fc_layer(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "1dImeVcipvar"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.Loss_Func & Optimizer"
      ],
      "metadata": {
        "id": "Qpmm8Bq2qfs1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bev0HGQepvcx",
        "outputId": "756e2656-3a00-4301-8458-03c81f20ab6f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = CNN().to(device)\n",
        "loss_func = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)"
      ],
      "metadata": {
        "id": "McnDKDc2pve-"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 지정한 스텝 단위로 학습률에 감마를 곱해 학습률을 감소시킨다.\n",
        "# scheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma= 0.99)       \n",
        "\n",
        "# 매 epoch마다 학습률에 감마를 곱한다.\n",
        "# scheduler = lr_scheduler.ExponentialLR(optimizer, gamma= 0.99)\n",
        "\n",
        "# 지정한 스텝 지점마다 학습률에 감마를 곱한다.\n",
        "# scheduler = lr_scheduler.MultiStepLR(optimizer, milestones=[10, 30, 80], gamma= 0.1)  \n",
        "\n",
        "scheduler = lr_scheduler.ReduceLROnPlateau(optimizer, threshold=1, patience=1, mode='min')\n",
        "print(dir(scheduler))\n",
        "print(dir(optimizer))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4zrXAOOsdfo",
        "outputId": "79dd21be-edd2-4e3e-bb1b-7797e0e0a986"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_init_is_better', '_reduce_lr', '_reset', 'best', 'cooldown', 'cooldown_counter', 'eps', 'factor', 'in_cooldown', 'is_better', 'last_epoch', 'load_state_dict', 'min_lrs', 'mode', 'mode_worse', 'num_bad_epochs', 'optimizer', 'patience', 'state_dict', 'step', 'threshold', 'threshold_mode', 'verbose']\n",
            "['__class__', '__delattr__', '__dict__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__getstate__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__lt__', '__module__', '__ne__', '__new__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__setstate__', '__sizeof__', '__str__', '__subclasshook__', '__weakref__', '_cuda_graph_capture_health_check', '_init_group', '_optimizer_step_code', '_optimizer_step_post_hooks', '_optimizer_step_pre_hooks', '_patch_step_function', '_warned_capturable_if_run_uncaptured', '_zero_grad_profile_name', 'add_param_group', 'defaults', 'load_state_dict', 'param_groups', 'profile_hook_step', 'register_step_post_hook', 'register_step_pre_hook', 'state', 'state_dict', 'step', 'zero_grad']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train"
      ],
      "metadata": {
        "id": "LGQwMawUqiWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(num_epoch):\n",
        "    for j, [image, label] in enumerate(train_loader):\n",
        "        x = image.to(device)\n",
        "        y_= label.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        output = model.forward(x)\n",
        "        loss = loss_func(output, y_)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "    scheduler.step(loss)\n",
        "    if i % 10 == 0:\n",
        "        print(loss)\n",
        "    print(\"Epoch: {}, Learning_Rate: {}\".format(i, scheduler.optimizer.state_dict()['param_groups'][0]['lr']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aIiWFkBgpvhC",
        "outputId": "a772ceff-045b-4332-b7d5-c490cde86922"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.2976, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "Epoch: 0, Learning_Rate: 0.001\n",
            "Epoch: 1, Learning_Rate: 0.0001\n",
            "Epoch: 2, Learning_Rate: 0.0001\n",
            "Epoch: 3, Learning_Rate: 1e-05\n",
            "Epoch: 4, Learning_Rate: 1e-05\n",
            "Epoch: 5, Learning_Rate: 1.0000000000000002e-06\n",
            "Epoch: 6, Learning_Rate: 1.0000000000000002e-06\n",
            "Epoch: 7, Learning_Rate: 1.0000000000000002e-07\n",
            "Epoch: 8, Learning_Rate: 1.0000000000000002e-07\n",
            "Epoch: 9, Learning_Rate: 1.0000000000000004e-08\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test"
      ],
      "metadata": {
        "id": "sFPYsQnzqjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for image, label in test_loader:\n",
        "        x = image.to(device)\n",
        "        y_= label.to(device)\n",
        "\n",
        "        output = model.forward(x)\n",
        "        _, output_index = torch.max(output, 1)\n",
        "        total += label.size(0)\n",
        "        correct += (output_index == y_).sum().float()\n",
        "        \n",
        "    print(\"Accuracy of Test Data: {}\".format(100*correct/total))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWSSQk2Tpvjq",
        "outputId": "92fbdb4e-5d7f-4517-8bd5-65c5803c0925"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Test Data: 9.57532024383545\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uDXhkswdqGKO"
      },
      "execution_count": 11,
      "outputs": []
    }
  ]
}